{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7037839",
   "metadata": {},
   "source": [
    "## AdamW — *Decoupled Weight Decay Regularization*\n",
    "\n",
    "O **AdamW** é uma modificação do Adam que **desacopla o decaimento de peso (*weight decay*)** do gradiente da perda.  \n",
    "Enquanto o Adam tradicional mistura o termo de regularização L2 com o gradiente, o AdamW aplica o decaimento separadamente, resultando em melhor generalização.\n",
    "\n",
    "O SGD com *weight decay* é definido como:\n",
    "\n",
    "$$\n",
    "\\theta_{t+1} = (1 - \\lambda) \\, \\theta_t - \\alpha \\, \\nabla f_t(\\theta_t)\n",
    "$$\n",
    "\n",
    "O que equivale a minimizar a função de custo com penalização L2:\n",
    "\n",
    "$$\n",
    "\\min_\\theta \\; f_t(\\theta) + \\frac{\\lambda'}{2} \\|\\theta\\|_2^2\n",
    "$$\n",
    "\n",
    "onde $\\lambda' = \\lambda / \\alpha$.\n",
    "\n",
    "No entanto, em otimizadores adaptativos (como o Adam), esse acoplamento causa um erro:  \n",
    "os pesos com menor gradiente recebem menos regularização, o que distorce o efeito do *weight decay*.\n",
    "\n",
    "---\n",
    "\n",
    "### Atualização do AdamW\n",
    "\n",
    "A atualização padrão do Adam é:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "m_t &= \\beta_1 m_{t-1} + (1 - \\beta_1) g_t \\\\\n",
    "v_t &= \\beta_2 v_{t-1} + (1 - \\beta_2) g_t^2 \\\\\n",
    "\\hat{m}_t &= \\frac{m_t}{1 - \\beta_1^t}, \\quad \\hat{v}_t = \\frac{v_t}{1 - \\beta_2^t}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Com o passo de atualização:\n",
    "\n",
    "$$\n",
    "\\theta_{t+1} = \\theta_t - \\eta \\, \\frac{\\hat{m}_t}{\\sqrt{\\hat{v}_t} + \\varepsilon}\n",
    "$$\n",
    "\n",
    "No AdamW, o *weight decay* é aplicado fora do passo adaptativo:\n",
    "\n",
    "$$\n",
    "\\theta_{t+1} = \\theta_t - \\eta \\, \\frac{\\hat{m}_t}{\\sqrt{\\hat{v}_t} + \\varepsilon} - \\eta \\, \\lambda \\, \\theta_t\n",
    "$$\n",
    "\n",
    "Essa separação garante que o *weight decay* seja constante por parâmetro e independente do histórico de gradientes.\n",
    "\n",
    "### Interpretação\n",
    "\n",
    "- O *learning rate* e o *weight decay* tornam-se hiperparâmetros mais independentes.  \n",
    "- Melhora a estabilidade e generalização em modelos grandes (ex.: CNNs e Transformers).  \n",
    "\n",
    "---\n",
    "\n",
    "## SAM — *Sharpness-Aware Minimization*\n",
    "\n",
    "O SAM busca minimizar a perda em regiões planas da superfície de otimização,  \n",
    "em vez de apenas encontrar o ponto de menor perda.  \n",
    "Isso aumenta a capacidade de generalização do modelo.\n",
    "\n",
    "\n",
    "### Formulação Min–Max\n",
    "\n",
    "O objetivo é minimizar a pior perda dentro de uma vizinhança de raio $\\rho$:\n",
    "\n",
    "$$\n",
    "\\min_w \\; \\max_{\\|\\varepsilon\\|_p \\le \\rho} \\; L_S(w + \\varepsilon)\n",
    "$$\n",
    "\n",
    "onde $L_S(w) = \\frac{1}{n} \\sum_i \\ell(w; x_i, y_i)$ é a perda média.\n",
    "\n",
    "### Aproximação do passo adversário\n",
    "\n",
    "Usando uma expansão de Taylor de primeira ordem, temos:\n",
    "\n",
    "$$\n",
    "L_S(w + \\varepsilon) \\approx L_S(w) + \\varepsilon^\\top \\nabla_w L_S(w)\n",
    "$$\n",
    "\n",
    "Maximizando em relação a $\\varepsilon$, obtemos o vetor adversário ótimo:\n",
    "\n",
    "$$\n",
    "\\hat{\\varepsilon}(w) = \\rho \\, \\frac{\\nabla_w L_S(w)}{\\|\\nabla_w L_S(w)\\|_2}\n",
    "$$\n",
    "\n",
    "\n",
    "### Gradiente aproximado do SAM\n",
    "\n",
    "O gradiente do objetivo suavizado é então aproximado por:\n",
    "\n",
    "$$\n",
    "\\nabla_w L_S^{\\text{SAM}}(w) \\approx \\nabla_w L_S(w + \\hat{\\varepsilon}(w))\n",
    "$$\n",
    "\n",
    "Na prática, isso leva a dois passos por iteração:\n",
    "\n",
    "1. Calcular o gradiente e dar um pequeno passo adversário:\n",
    "   $$\n",
    "   w' = w + \\rho \\, \\frac{\\nabla_w L_S(w)}{\\|\\nabla_w L_S(w)\\|_2}\n",
    "   $$\n",
    "\n",
    "2. Calcular novamente o gradiente no ponto perturbado $w'$ e atualizar:\n",
    "   $$\n",
    "   w \\leftarrow w - \\eta \\, \\nabla_w L_S(w')\n",
    "   $$\n",
    "\n",
    "### Interpretação\n",
    "\n",
    "- O SAM evita soluções muito “agudas” (*sharp minima*).  \n",
    "- Aumenta a robustez e generalização, especialmente em datasets grandes.  \n",
    "- Normalmente é usado com AdamW ou SGD como otimizador base.  \n",
    "\n",
    "---\n",
    "\n",
    "### Atualização final com SAM + AdamW\n",
    "\n",
    "$$\n",
    "\\theta_{t+1} = \\theta_t - \\eta \\, \\frac{\\hat{m}_t}{\\sqrt{\\hat{v}_t} + \\varepsilon} - \\eta \\, \\lambda \\, \\theta_t\n",
    "\\quad \\text{com} \\quad\n",
    "g_t = \\nabla_\\theta L_S(w + \\hat{\\varepsilon}(w))\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e703256",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8d68886",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAM(torch.optim.Optimizer):\n",
    "    def __init__(self, params, base_optimizer, rho=0.05, **kwargs):\n",
    "        if not 0.0 <= rho:\n",
    "            raise ValueError(f\"Invalid rho: {rho}\")\n",
    "        self.rho = rho\n",
    "        # cria o otimizador base\n",
    "        self.base_optimizer = base_optimizer(params, **kwargs)\n",
    "        # inicializa o construtor da superclasse (necessário pro zero_grad funcionar)\n",
    "        defaults = dict(rho=rho, **kwargs)\n",
    "        super().__init__(self.base_optimizer.param_groups, defaults)\n",
    "        # o SAM mantém a mesma lista de grupos de parâmetros\n",
    "        self.param_groups = self.base_optimizer.param_groups\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def first_step(self, zero_grad=False):\n",
    "        grad_norm = torch.norm(\n",
    "            torch.stack([\n",
    "                p.grad.norm(p=2) for group in self.param_groups for p in group[\"params\"] if p.grad is not None\n",
    "            ])\n",
    "        )\n",
    "        scale = self.rho / (grad_norm + 1e-12)\n",
    "\n",
    "        for group in self.param_groups:\n",
    "            for p in group[\"params\"]:\n",
    "                if p.grad is None: \n",
    "                    continue\n",
    "                e_w = p.grad * scale.to(p)\n",
    "                p.add_(e_w)\n",
    "                self.state[p][\"e_w\"] = e_w\n",
    "\n",
    "        if zero_grad:\n",
    "            self.zero_grad()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def second_step(self, zero_grad=False):\n",
    "        for group in self.param_groups:\n",
    "            for p in group[\"params\"]:\n",
    "                if p.grad is None: \n",
    "                    continue\n",
    "                p.sub_(self.state[p][\"e_w\"])\n",
    "        self.base_optimizer.step()\n",
    "        if zero_grad:\n",
    "            self.zero_grad()\n",
    "\n",
    "    def zero_grad(self):\n",
    "        self.base_optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96a1ae8",
   "metadata": {},
   "source": [
    "## Lion\n",
    "\n",
    "O Lion (*Evolved Sign Momentum Optimizer*) é um otimizador recente proposto por Chen et al. (2023) que busca combinar o desempenho de métodos adaptativos (como AdamW) com a simplicidade e eficiência de uso de memória de métodos baseados em sinal, como o *signSGD*.  \n",
    "\n",
    "Seu nome vem da ideia de usar apenas o sinal do gradiente com momentum, reduzindo a dependência de operações de raiz quadrada e variância, e mantendo um comportamento estável em larga escala.\n",
    "\n",
    "---\n",
    "\n",
    "### Motivação\n",
    "\n",
    "O Adam e outros otimizadores adaptativos apresentam dois problemas práticos:\n",
    "1. Consomem muita memória, pois armazenam dois momentos (primeiro e segundo) para cada parâmetro.\n",
    "2. Possuem comportamento sensível ao *weight decay* e às escalas dos gradientes.\n",
    "\n",
    "O Lion propõe uma atualização mais simples, que mantém a essência do *momentum adaptativo* sem depender da variância dos gradientes.\n",
    "\n",
    "---\n",
    "\n",
    "### Atualização do Lion\n",
    "\n",
    "O Lion mantém um vetor de média móvel do gradiente $m_t$, como o Adam,  \n",
    "mas a atualização dos pesos depende apenas do sinal de $m_t$:\n",
    "\n",
    "$$\n",
    "m_t = \\beta_1 m_{t-1} + (1 - \\beta_1) g_t\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\theta_{t+1} = \\theta_t - \\eta \\, \\text{sign}(m_t) - \\eta \\, \\lambda \\, \\theta_t\n",
    "$$\n",
    "\n",
    "onde:\n",
    "- $\\text{sign}(m_t)$ retorna apenas o sinal de cada componente (+1 ou -1),\n",
    "- $\\eta$ é a taxa de aprendizado,\n",
    "- $\\lambda$ é o *weight decay*,\n",
    "- $\\beta_1$ controla o momentum, e \\( \\beta_2 \\) o amortecimento adicional do histórico.\n",
    "\n",
    "Na versão final do artigo, o Lion usa uma combinação dupla de momentum:\n",
    "\n",
    "$$\n",
    "m_t = \\beta_1 m_{t-1} + (1 - \\beta_1) g_t \\\\\n",
    "\\theta_{t+1} = \\theta_t - \\eta \\, (\\text{sign}(m_t) + \\beta_2 m_{t-1})\n",
    "$$\n",
    "\n",
    "\n",
    "### Intuição\n",
    "\n",
    "- O sinal do gradiente fornece uma direção robusta,  \n",
    "  eliminando a influência da magnitude e reduzindo oscilações.\n",
    "- O momentum acumula a direção predominante do aprendizado.\n",
    "- Ao misturar ambos, o Lion consegue passos estáveis e consistentes,  \n",
    "  especialmente em arquiteturas profundas como ViT e modelos de difusão.\n",
    "\n",
    "\n",
    "### Benefícios\n",
    "\n",
    "- Baixo custo computacional: não calcula ou armazena o segundo momento.\n",
    "- Baixo uso de memória: apenas um vetor de momentum por parâmetro.\n",
    "- Generalização comparável (ou melhor) que AdamW em vários benchmarks.\n",
    "- Compatível com *weight decay* desacoplado (como no AdamW).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e5eb950",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lion(torch.optim.Optimizer):\n",
    "    def __init__(self, params, lr=1e-4, betas=(0.9, 0.99), weight_decay=0.0):\n",
    "        defaults = dict(lr=lr, betas=betas, weight_decay=weight_decay)\n",
    "        super().__init__(params, defaults)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def step(self):\n",
    "        for group in self.param_groups:\n",
    "            lr, (b1, b2), wd = group[\"lr\"], group[\"betas\"], group[\"weight_decay\"]\n",
    "            for p in group[\"params\"]:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                grad = p.grad\n",
    "                state = self.state[p]\n",
    "\n",
    "                if len(state) == 0:\n",
    "                    state[\"exp_avg\"] = torch.zeros_like(p)\n",
    "\n",
    "                exp_avg = state[\"exp_avg\"]\n",
    "                exp_avg.mul_(b1).add_(grad, alpha=1 - b1)\n",
    "\n",
    "                update = exp_avg.sign().add(p, alpha=wd)\n",
    "                p.add_(update, alpha=-lr)\n",
    "                exp_avg.mul_(b2).add_(grad, alpha=1 - b2)"
   ]
  }
